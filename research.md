---
layout: page
title: Research
---

My research focuses on utilising machine learning techniques to extract insightful representations of large and complex data coming from heterogeneous data streams (wearables, cameras, LiDAR) embedded in intelligent systems (e.g. robots, drones, smart homes). The aim is mostly to achieve a better understanding of the environments where these sensors, as well as the whole system, are deployed; and to maximise the reward / return of the task of interests (e.g. robot exploration in human-centered environments is to maximise human-robot interactions).

## Current Projects

<p class="message">
  I currently have no active projects. I will update this page once I have project(s) to share.
</p>

## Past Projects


### <a href="https://www.bristol.ac.uk/engineering/research/digital-health/research/sphere/">PD-SENSORS</a> (<a href="https://gow.epsrc.ukri.org/NGBOViewGrant.aspx?GrantRef=EP/R005273/1">SPHERE Project</a>) 

<img style="float: left; padding: 3px 5px 0px 0px;" src="{{ '/' | relative_url }}public/pd-sensors.png" width="400" /> The vision of the EPSRC-funded SPHERE IRC is to impact a range of healthcare needs by employing data-fusion and pattern-recognition from a common platform of sensors in the home. One application is to continuously monitor the progression of Parkinson's disease more accurately, without being afraid of hour/daily fluctuations. PD-SENSORS project initiates the first step towards autonomous evaluations of persons with Parkinson's disease using multi-sensory data from SPHERE houses.


### <a href="https://gtr.ukri.org/projects?ref=104821#/tabOverview">MIMRee</a>

<div style="float: left; padding: 8px 5px 0px 0px;"><iframe width="400" height="225" src="https://www.youtube.com/embed/slLLaByFN28?si=jw75K8YEZH1vY_oQ" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe></div>
MIMRee (Multi-Platform Inspection, Maintenance & Repair in Extreme Environments) is a £4.2m project funded by Innovate UK and industry and focuses on building the world's first fully autonomous and comprehensive multi-robotic platform for the inspection, maintenance and repair of offshore wind farms. In this project, I was involved in creating a planning and coordination technology for the various robotic assets, which include drones, an autonomous surface vessel, a climbing inspection and maintenance robot and multi-functional arm. I am also responsible for the human-robot interface.


### <a href="https://prometheusdrone.co.uk/">Prometheus</a>

<div style="float: left; padding: 8px 5px 0px 0px;"><iframe width="400" height="225" src="https://www.youtube.com/embed/BeumYmIAl6Q?si=UP92RCdJuctzMtQ4" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe></div>
Prometheus is a £2m project funded by Innovate UK and industry and focuses on building an intelligent reconfigurable drone for the exploration of confined spaces, such as underground mines. In this project, I was involved in co-creating the intelligent exploration and autonomous navigation of the drone in confined spaces.


### <a href="http://strands.acin.tuwien.ac.at/">STRANDS</a>

<img style="float: left; padding: 3px 5px 0px 0px;" src="{{ '/' | relative_url }}public/strands.jpg" width="400" />
STRANDS will produce intelligent mobile robots that are able to run for months in dynamic human environments. The project aims to provide robots with the longevity and behavioural robustness necessary to make them truly useful assistants in a wide range of domains. Such long-lived robots will be able to learn from a wider range of experiences than has previously been possible, creating a whole new generation of autonomous systems able to extract and exploit the structure in their worlds. In this project, I was responsible in creating statistical models that can capture reliably and summarize the aggregate human occupancy behaviour through various data streams. The models were used to drive task planning technology towards prioritising tasks that maximise robot learning and human-robot interactions.




